version: '2'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka:
    image: confluentinc/cp-kafka:latest
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092, PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT, PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_LOG_RETENTION_BYTES: 2000000000
    ports:
      - "127.0.0.1:29092:29092"

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.0.0
    restart: unless-stopped
    environment:
      - cluster.name=cert-cluster
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms1024m -Xmx1024m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - esdata_node:/usr/share/elasticsearch/data
    ports:
      - "127.0.0.1:9200:9200"

  kibana:
    image: docker.elastic.co/kibana/kibana:7.0.0
    restart: unless-stopped
    links:
      - elasticsearch
    volumes:
      - "./kibana/kibana.yml:/usr/share/kibana/config/kibana.yml"
    ports:
      - "127.0.0.1:5601:5601"

  logstash:
    image: docker.elastic.co/logstash/logstash:7.0.0
    links:
      - elasticsearch
      - kafka
    volumes:
      - "./logstash/conf.d:/usr/share/logstash/pipeline"

volumes:
  esdata_node:
    driver: local
